---
title: "Unsupervised Learning Analysis of Cancer Cells"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Import the data
```{r}
wisc.df <- read.csv("WisconsinCancer.csv") 

#convert features (col3 to 32) of data to matrix
wisc.data <- as.matrix(wisc.df[,3:32]) 
#alternatively, as.matrix(wisc.df[,-c(1:2)])

#set row names of wisc.data
row.names(wisc.data) <- wisc.df$id

#create diagnosis vector
diagnosis <- as.numeric(wisc.df$diagnosis == "M")
sum(diagnosis) #confirm how many are malignant
```

How many observations are in this dataset?
```{r}
nrow(wisc.data)
length(diagnosis)
```

How many variables/features in the data are suffixed with _mean?
```{r}
length(grep("_mean", colnames(wisc.data)))
```

How many observations have a malignant diagnosis?
```{r}
sum(diagnosis)
```

## Performing PCA
Check the mean and stdev of features in wisc.data to determine
if needed to be scaled
```{r}
means <- colMeans(wisc.data) #get column means of wisc.data
plot(means, type="o") #plot to see if we need to do scaling

apply(wisc.data,2,sd)
```

Excute PCA to wisc.data
```{r}
wisc.pr <- prcomp(wisc.data, scale = TRUE) #perform pca using prcomp
#if there are NA's in the data, will get error message
#remove NA's before performing PCA

summary(wisc.pr) #view a summary of the pca
```


Interpreting PCA results
```{r}
biplot(wisc.pr) #biplot of PCA results
```

```{r}
#Generate a more standard scatter plot for observations 1&2
plot(wisc.pr$x[, c(1,2)], col= (diagnosis + 1),
     xlab = "PC1", ylab = "PC2")

#Generate scatter plot for observations 1&3
plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1), 
     xlab = "PC1", ylab = "PC3")
```

Examine "elbow" of the data
```{r}
pr.var <- wisc.pr$sdev^2 #find variance of the data
pve <- pr.var/sum(pr.var) #calculate variance explained by each PC

#plot the percent variance
prop_var <- plot(pve,
         xlab = "PC", ylab = "Porportion of Variance Explained",
         ylim = c(0, 1), type = "o")
```

Create bar plot for the data
```{r}
barplot(pve, ylab = "Precent of Variance Explained",
        names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
#las=2 means vertical labels
#axes=FALSE means to turn off the y axis so we can add a better one

#add new y axis
axis(2, at=pve, labels=round(pve,2)*100 )
#axis (#) changes where the axis goes
#at = where the ticks are going
#labels = where the numbers will be, multiply by 100 to show percent
```


Plot cumulative proportion of variance explained
```{r}
cum_var <- plot(cumsum(pve), xlab = "PC", ylab = "Cumulative Proportion of Variance             Explained",
            ylim = c(0,1), type = "o")
```

Section 3
Hierarchical clustering of case data
```{r}
data.scaled <- scale(wisc.data) #scale data
data.dist <- dist(data.scaled) #calculate euclidean distance btw pairs of obs
wisc.hclust <- hclust(data.dist, method = "complete") #do hclust on data
plot(wisc.hclust) #plot the dendrogram
abline(h=20, col="red")
```

Selecting number of clusters
```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4) #cut hclust into 4 clusters
#use table() fxn to compare cluster membership to actual diagnosis
table(wisc.hclust.clusters, diagnosis)

#cut tree into 2 clusters
wisc.hclust.2clusters <- cutree(wisc.hclust, k=2)
table(wisc.hclust.2clusters, diagnosis)

#cut tree into 3 clusters
wisc.hclust.3clusters <- cutree(wisc.hclust, k=3)
table(wisc.hclust.3clusters, diagnosis)

#cut tree into 5 clusters
wisc.hclust.5clusters <- cutree(wisc.hclust, k=5)
table(wisc.hclust.5clusters, diagnosis)
```

Section 4
K-means clustering and comparing results
```{r}
wisc.km <- kmeans(data.scaled, centers = 2, nstart = 20)
#centers = k
#nstart = how many runs to repeat this

#compare our 2 km clusters to diagnosis
table(wisc.km$cluster, diagnosis)
```

```{r}
#compare clusters from kmeans model to clusters for hc model
table(wisc.hclust.clusters, wisc.km$cluster)
```


Section 5
Clustering on PCA results
Make the clusters more apparent by using PCA to cluster
```{r}
# Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:3]), method = "ward.D2")
plot(wisc.pr.hclust)
```

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=4)
#cut into 4 clusters

plot(wisc.pr$x[,1:2], col=wisc.pr.hclust.clusters)

table(wisc.pr.hclust.clusters, diagnosis)
```

```{r}
library(rgl)

#create a 3d plot for the clusters using rgl
plot3d(wisc.pr$x[,1:2], type = "s", col = wisc.pr.hclust.clusters)
```

```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata = new)

plot(wisc.pr$x[,1:2], col=wisc.pr.hclust.clusters)
points(npc[,1], npc[,2], col=c("orange", "pink"), pch=16, cex=3)
```







